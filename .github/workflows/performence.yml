name: ğŸ“ˆ Performance Testing

on:
  workflow_dispatch:
    inputs:
      duration:
        description: 'Test duration in seconds'
        required: true
        default: '300'
        type: string
      concurrent_users:
        description: 'Number of concurrent users'
        required: true
        default: '10'
        type: string

jobs:
  performance-test:
    name: ğŸš€ Load & Performance Test
    runs-on: ubuntu-latest
    
    steps:
    - name: ğŸ“¥ Checkout repository
      uses: actions/checkout@v4
      
    - name: ğŸ³ Start monitoring stack
      run: |
        echo "ğŸš€ Starting monitoring stack..."
        docker compose up -d
        sleep 60
        
        echo "ğŸ” Verifying services are ready..."
        docker compose ps
        
    - name: ğŸ“Š Install performance tools
      run: |
        sudo apt-get update
        sudo apt-get install -y apache2-utils curl jq
        
    - name: ğŸ§ª Pre-test Health Check
      run: |
        echo "ğŸ§ª Running pre-test health checks..."
        curl -f http://localhost:7070 || exit 1
        curl -f http://localhost:9090/-/healthy || exit 1
        curl -f http://localhost:3000/api/health || exit 1
        echo "âœ… All services healthy, starting performance test..."
        
    - name: ğŸš¨ Execute Load Test
      run: |
        echo "ğŸš¨ Starting load test..."
        echo "â±ï¸  Duration: ${{ github.event.inputs.duration }}s"
        echo "ğŸ‘¥ Concurrent users: ${{ github.event.inputs.concurrent_users }}"
        echo "ğŸ¯ Target: http://localhost:7070"
        echo ""
        
        # Apache Bench comprehensive test
        ab -t ${{ github.event.inputs.duration }} \
           -c ${{ github.event.inputs.concurrent_users }} \
           -g performance_results.tsv \
           -e performance_percentiles.csv \
           http://localhost:7070/ > ab_results.txt
        
        echo "âœ… Load test completed!"
        
    - name: ğŸ“Š Collect Performance Metrics
      run: |
        echo "ğŸ“Š Collecting performance metrics from Prometheus..."
        
        # Request rate during test
        curl -s "http://localhost:9090/api/v1/query?query=rate(nginx_http_requests_total[1m])" > request_rate.json
        
        # Active connections
        curl -s "http://localhost:9090/api/v1/query?query=nginx_connections_active" > connections.json
        
        # Response status codes
        curl -s "http://localhost:9090/api/v1/query?query=nginx_http_requests_total" > status_codes.json
        
        echo "âœ… Metrics collected successfully!"
        
    - name: ğŸ“ˆ Generate Performance Report
      run: |
        echo "ğŸ“ˆ Generating comprehensive performance report..."
        
        cat << 'EOF' > performance_report.md
        # ğŸ“ˆ Performance Test Report
        
        **Test Date**: $(date)  
        **Duration**: ${{ github.event.inputs.duration }} seconds  
        **Concurrent Users**: ${{ github.event.inputs.concurrent_users }}  
        **Target URL**: http://localhost:7070
        
        ## ğŸ¯ Test Configuration
        - **Tool**: Apache Bench (ab)
        - **Total Time**: ${{ github.event.inputs.duration }}s
        - **Concurrency Level**: ${{ github.event.inputs.concurrent_users }}
        - **Keep-Alive**: Yes
        
        ## ğŸ“Š Apache Bench Results
        \`\`\`
        EOF
        
        cat ab_results.txt >> performance_report.md
        
        echo '```' >> performance_report.md
        echo "" >> performance_report.md
        echo "## ğŸ“ˆ Key Performance Metrics" >> performance_report.md
        echo "" >> performance_report.md
        
        # Extract key metrics from ab results
        REQUESTS_TOTAL=$(grep "Complete requests:" ab_results.txt | awk '{print $3}')
        REQUESTS_FAILED=$(grep "Failed requests:" ab_results.txt | awk '{print $3}')
        REQUESTS_PER_SEC=$(grep "Requests per second:" ab_results.txt | awk '{print $4}')
        TIME_PER_REQUEST=$(grep "Time per request:" ab_results.txt | head -1 | awk '{print $4}')
        
        echo "- **Total Requests**: $REQUESTS_TOTAL" >> performance_report.md
        echo "- **Failed Requests**: $REQUESTS_FAILED" >> performance_report.md  
        echo "- **Requests/Second**: $REQUESTS_PER_SEC" >> performance_report.md
        echo "- **Time/Request**: $TIME_PER_REQUEST ms" >> performance_report.md
        echo "" >> performance_report.md
        
        echo "## ğŸ” Prometheus Metrics Analysis" >> performance_report.md
        echo "" >> performance_report.md
        echo "### Request Rate" >> performance_report.md
        echo '```json' >> performance_report.md
        cat request_rate.json | jq '.' >> performance_report.md
        echo '```' >> performance_report.md
        
        echo "### Active Connections" >> performance_report.md  
        echo '```json' >> performance_report.md
        cat connections.json | jq '.' >> performance_report.md
        echo '```' >> performance_report.md
        
        echo "## ğŸ¯ Test Summary" >> performance_report.md
        echo "" >> performance_report.md
        if [ "$REQUESTS_FAILED" = "0" ]; then
          echo "âœ… **Result**: All requests completed successfully!" >> performance_report.md
        else
          echo "âš ï¸  **Result**: $REQUESTS_FAILED requests failed out of $REQUESTS_TOTAL" >> performance_report.md
        fi
        
        echo "ğŸ“Š **Performance Rating**: " >> performance_report.md
        if (( $(echo "$REQUESTS_PER_SEC > 100" | bc -l) )); then
          echo "ğŸš€ Excellent (>100 req/s)" >> performance_report.md
        elif (( $(echo "$REQUESTS_PER_SEC > 50" | bc -l) )); then
          echo "âœ… Good (>50 req/s)" >> performance_report.md
        else
          echo "âš¡ Needs optimization (<50 req/s)" >> performance_report.md
        fi
        
    - name: ğŸ“¤ Upload Performance Artifacts
      uses: actions/upload-artifact@v3
      with:
        name: performance-test-results
        path: |
          performance_report.md
          performance_results.tsv
          performance_percentiles.csv
          ab_results.txt
          request_rate.json
          connections.json
          status_codes.json
          
    - name: ğŸ“‹ Performance Summary
      run: |
        echo "ğŸ‰ Performance test completed successfully!"
        echo ""
        echo "ğŸ“Š Quick Stats:"
        grep "Requests per second:" ab_results.txt
        grep "Time per request:" ab_results.txt | head -1
        grep "Complete requests:" ab_results.txt
        grep "Failed requests:" ab_results.txt
        echo ""
        echo "ğŸ“ Detailed results uploaded as artifacts"
        echo "ğŸ“ˆ Check the performance_report.md for full analysis"
        
    - name: ğŸ§¹ Cleanup
      if: always()
      run: |
        echo "ğŸ§¹ Cleaning up test environment..."
        docker compose down -v
        docker system prune -f
        echo "âœ… Cleanup completed!"